\documentclass[10pt,a4paper,final]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[main=portuguese, english]{babel}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{enumitem}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{scrbase}

\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},   
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\small,
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,
    frame=single,
    keepspaces=true,                 
    numbers=left,                    
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=2
}

\newcaptionname{portuguese}{\lstlistingname}{Listagem}
\newcaptionname{portuguese}{\lstlistlistingname}{Listagens}


\lstset{style=mystyle}


\author{Cristhian Grundmann}
\title{Visualização de curvas e superfícies a partir de geodésicas}


\begin{document}

\maketitle

\tableofcontents
\lstlistoflistings
\listoffigures
\listoftables


\section{Gramática de descrição de objetos}
A gramática permite a declaração de 8 tipos de objeto: parâmetro, curva, superfície, definição, função, grade, ponto e vetor.

Os objetos podem fazer referência apenas a objetos definidos anteriormente, porém apenas pontos e vetores podem se referir a grades, diretamente ou indiretamente.

A gramática descreve duas estruturas principais: as declarações dos objetos(\texttt{DECL}) e as expressões matemáticas(\texttt{ADD}). As declarações têm estrutura simples, já as expressões são mais complexas.

A gramática das expressões matemáticas é mais especial quando comparada às linguagens de programação gerais, pois o domínio desse projeto é muito mais limitado. As partes não usuais são:

\begin{itemize}
\item Multiplicação justaposta: \texttt{2 x y z}
\item Função sem parênteses: \texttt{sin -x}
\item Recíproco unário: \texttt{/x = 1/x}
\item Múltiplicação unária(sem efeito): \texttt{*x = x}
\item Potenciação e derivação em funções: \texttt{f\textasciicircum 2 x}, \texttt{sin' x}
\end{itemize}

\newpage
\lstinputlisting[caption=Gramática completa]{grammar.txt}

\section{Processamento da descrição}
Há um pequeno detalhe a ser notado antes de se fazer o \textit{parsing} da descrição: não é possível determinar se um lexema como \texttt{k} forma um token do tipo \texttt{var\_id}, \texttt{func\_id} ou \texttt{id}. Isso é um problema pois a expressão \texttt{k 2} pode representar uma multiplicação ou uma aplicação de função, dependendo do tipo de \texttt{k}. A declaração do objeto determina seu tipo, então a análise léxica(que lê o texto e produz tokens adequados) e a análise sintática(que lê a sequência de tokens e produz uma estrutura de dados) deverão trabalhar em sincronia. O lexer e o parser devem compartilhar uma \textit{tabela de símbolos}, indicando quais símbolos(identificadores) estão definidos e quais são seus tipos. Quando o parser termina de processar a declaração de \texttt{k}, ele o põe na tabela de símbolos com o tipo adequado. Durante a leitura da declaração, o lexer lia \texttt{k} como um token do tipo \texttt{id}, que serve para indicar um símbolo novo. Depois da declaração, o lexer passará a ler \texttt{k} como \texttt{var\_id} ou \texttt{func\_id}, dependendo da declaração.

Para processar uma declaração de função \texttt{f}, a lista de argumentos é uma sequência de tokens do tipo \texttt{id}. Ao ler um argumento, o parser o coloca na tabela de símbolos como \texttt{var\_id}, impedindo a repetição de argumentos e possibilitando a referência no corpo da função. Após a declaração, os símbolos que serviram como argumento são removidos da tabela, pois são dummies.

O método de parsing usado é o recursive descent, onde cada não-terminal é uma rotina que lê uma sentença de seu tipo. Essas rotinas possuem efeitos colaterais, por isso não são chamadas de funções. Por exemplo, a rotina \texttt{FACT} examina o token atual, e consegue determinar qual produção gramatical deve ser utilizada. Caso seja \texttt{TUPLE}, sua rotina é chamada para ler uma tupla. Caso seja outra produção, a rotina consome e processa o token, mandando o lexer passar para o próximo.


\end{document}